---
layout: post
title: Implementation of PSO
date: 2023-04-08 15:09:00
description: implementation of PSO with dynamic social and cognitive parameters
tags: Python particle-simulation
categories: bio-inspired-computing
featured: true
---

The **Particle Swarm Optimization (PSO)** [[2](https://en.wikipedia.org/wiki/Particle_swarm_optimization)] is a bio-inspired algorithm, 
it tries to mimic the *flocking behaviour of birds*. This algorithm can be used to solve optimization problems (e.g. the travelling salesman problem). 


The initial position of the birds (particles) are randomly generated. To mimic the birds flocking behaviour, the algorithm takes into account three aspects:
- **separation**: maintain a certain distance from the other birds
- **alignment**: align the velocity with the other birds
- **cohesion**: move towards the centre of mass of the other birds

In the literature, different implementations of the PSO algorithm. Also, research has proven that given a specific problem the performance of the algorithm can be improved by changing the topology [[1](https://link.springer.com/chapter/10.1007/978-3-319-11857-4_16)]. The topology of the PSO is the way the birds are connected and how they influence each other. 

The algorithm has been influential in solving a wide range of problems, from engineering to economics and more [[3](https://onlinelibrary.wiley.com/doi/10.1155/2008/685175)]. One of the candidate interpretations of the pseudo-code of the algorithm is available here [[4](https://en.wikipedia.org/wiki/Particle_swarm_optimization)].

At each step the algorithm, to update the position of the birds, uses the following equation:

$$
\begin{equation}
    \vec{x}_{i}^{t+1} = \vec{x}_{i}^{t} + \vec{v}_{i}^{t+1}
\end{equation}
$$

where $\vec{x}_{i}^{t}$ is the position of the $i$-th bird at time $t$ and $\vec{v}_{i}^{t+1}$ is the velocity of the $i$-th bird at time $t+1$. The **standard PSO algorithm** to update the velocity of the birds uses the following equation:

$$
\begin{equation}
    \vec{v}_{i}^{t+1} = \omega \vec{v}_{i}^{t} + c_{1} r_{1} (\vec{p}_{i}^{t} - \vec{x}_{i}^{t}) + c_{2} r_{2} (\vec{p}_{g}^{t} - \vec{x}_{i}^{t})
\end{equation}
$$

Where:
- $\vec{v}_{i}^{t}$ is the velocity of the $i$-th bird at time $t$
- $\vec{x}_{i}^{t}$ is the position of the $i$-th bird at time $t$
- $\vec{p}_{i}^{t}$ is the best position of the $i$-th bird at time $t$
- $\vec{p}_{g}^{t}$ is the best position of the group at time $t$
- $\omega$ is the inertia weight
- $c_{1}$ and $c_{2}$ are the cognitive and social parameters
- $r_{1}$ and $r_{2}$ are random numbers in the range $[0,1]$ sampled from a uniform distribution


The velocity take into account:
- inertia velocity: $\omega \vec{v}_{i}^{t}$
- cognitive velocity: $c_{1} r_{1} (\vec{p}_{i}^{t} - \vec{x}_{i}^{t})$
- social velocity: $c_{2} r_{2} (\vec{p}_{g}^{t} - \vec{x}_{i}^{t})$

In general, on hard multimodal problems being able to escape from local minima is a key aspect ($r_{2} > r_{1}$). The cognitive velocity summarizes the knowledge of the bird about its best position. While the social velocity summarizes the knowledge of the bird about the best position of the group. By the group we mean the birds that are connected to the bird. This aspect is related to the topology of the PSO. For example, the birds can be connected in a ring, in a star, in a wheel, etc. Also, the inertia velocity is used to escape from local minima. It measures the tendency of the bird to keep moving.

Select the right values for the parameters $c_{1}$, $c_{2}$, $r_{1}$, $r_{2}$ and $\omega$ is not trivial. The performance of the algorithm is highly dependent on the parameters. In the literature can be found different approaches to select the parameters. For instance, the inertia weight can be selected as a linearly decreasing function of the number of iterations. 

##### Python implementation


One of the most common implementations of the PSO algorithm can be found in the following [here](https://towardsdatascience.com/swarm-intelligence-coding-and-visualising-particle-swarm-optimisation-in-python-253e1bd00772). This implementation, on the other hand, considers to update the velocity of the birds (equation 2) using dynamic social and cognitive parameters ($r_{1}$ and $r_{2}$). 

Import the required libraries:

```python
import numpy as np
import random
from matplotlib import pyplot as plt
from matplotlib import animation
from numpy import exp
from numpy import sqrt
from numpy import cos
from numpy import e
from numpy import pi
```

The following function is used to update the position of the birds:

```python
def update_p(particle, velocity):
  """Update the position of the particles

  Args:
    particle: current position of the particles
    velocity: velocity of the particles

  Output:
    _ : updated position of the particles

  """
  return particle + velocity
```

The following function is used to update the velocity of the birds:

```python
def update_v(velocity, particles, pbest, gbest):
  """ Update the velocity of the particles
  Implementation slide 12 group of slide
  on particle swarm optimization

  Args:
    velocity: velocity of the particles
    particles: current position of the particles
    pbest: best position of the particles
    gbest: best position of the swarm

  Output:
    new_velocity: updated velocity of the particles

  """
  # number of particles
  n_particles = len(particles)

  # fi determine the particle trajectory
  fi = random.uniform(0.1, 0.4)

  # initialize the weight formula 
  # slide 14 (convergence condition)
  w = random.uniform((0.5*(fi+fi)), 1)

  # initialize the velocity to zero
  new_velocity = np.array([0.0 for _ in range(n_particles)])

  # random number piked from a uniform distribution
  u1 = random.uniform(0,1)
  u2 = random.uniform(0,1)

  # update the velocity
  for i in range(n_particles):
    # slide 12
    new_velocity[i] = w * velocity[i] + fi * u1 * (pbest[i] - particles[i]) + fi * u2 * (gbest[i] - particles[i])

  return new_velocity
```

Afterwards, to benchmark the algorithm, we can use the following fitness function:

```python
def fitness_fn(x,y):
  """Fitness function"""
  # Ackley
  return -20.0 * exp(-0.2 * sqrt(0.5 * (x**2 + y**2))) - exp(0.5 * (cos(2 * pi * x) + cos(2 * pi * y))) + e + 20
  # Griewank
  # source: https://spotpy.readthedocs.io/en/latest/Griewank/
  # return 1 + (x**2 + y**2)/4000 - cos(x/sqrt(2))*cos(y/sqrt(3))+1
  # Schwefel
  # return 418.9829*2 - x * sin( sqrt( abs( x )))-y*sin(sqrt(abs(y)))
  # Rosenbrock
  # source: https://spotpy.readthedocs.io/en/latest/Rosenbrock/
  # return (1-x)**2 + 100*(y-x**2)**2
  # Rastrigin 
  # return 10*2 + x**2 + y**2 - 10*cos(2*pi*x) - 10*cos(2*pi*y)
```

*Note: the fitness function can be changed to benchmark the algorithm on different problems. You could also write your own fitness function to benchmark the algorithm on a specific problem.*

Then, the following function is used to initialize the particles and start the optimization process:

```python
def fit(population: int = 30, dimension: int = 2, generation: int = 100, pos_min: int = -200, pos_max: int = 200):

  # Plotting prepartion
  fig = plt.figure(figsize=(10, 10))
  ax = fig.add_subplot(111, projection='3d')
  ax.set_xlabel('x')
  ax.set_ylabel('y')
  ax.set_zlabel('z')
  x = np.linspace(pos_min, pos_max, 100)
  y = np.linspace(pos_min, pos_max, 100)
  X, Y = np.meshgrid(x, y)
  Z= fitness_fn(X,Y)
  ax.plot_wireframe(X, Y, Z, color='r', linewidth=0.2)

  # Animation image placeholder
  images = []

  # initialize the population
  particles = [[random.uniform(pos_min, pos_max) for j in range(dimension)] for i in range(population)]

  # compute the fitness of the particles
  pfitness = [fitness_fn(p[0],p[1]) for p in particles]

  # index particle with the best fitness
  index_gbest = np.argmin(pfitness)

  # position of the particle with the best fitness
  position_gbest = particles[index_gbest]

  # initialize the velocity equal to zero
  velocity = [[0.0 for j in range(dimension)] for i in range(population)]

  for _ in range(generation):

    for i in range(population):
      # update the velocity
      velocity[i] = update_v(velocity[i], particles[i], particles[i], position_gbest)

      # update the position
      particles[i] = update_p(particles[i], velocity[i])


    # Plotting
    image = ax.scatter3D([particles[n][0] for n in range(population)],
                        [particles[n][1] for n in range(population)],
                        [fitness_fn(particles[n][0],particles[n][1]) for n in range(population)], c='b')
    images.append([image])

    # compute the fitness of the particles
    pfitness = [fitness_fn(p[0],p[1]) for p in particles]

    # index particle with the best fitness
    index_gbest = np.argmin(pfitness)

    # position of the particle with the best fitness
    position_gbest = particles[index_gbest]

  # Generate the animation image and save
  animated_image = animation.ArtistAnimation(fig, images, interval=5, blit=True, repeat_delay=1000)
  animated_image.save(f'./gif_pso_swarm_simulation{problem}.mp4', fps=20) 

  return position_gbest, pfitness[index_gbest], np.average(pfitness), images
```

To visualize the optimization process we can rely on the `animation.ArtistAnimation` which allows to generate a gif/mp4 file. 

To run the algorithm we can do the following:

```python
position_gbest, pfitness, average_fitness, images = fit()
```

##### Results

The figures compare on the left the implementation of the PSO with $r_{1}$, $r_{2}$ uniformly sampled from a uniform distribution in the range $[0.1,0.4]$. On the right, the implementation of the PSO with $r_{1}$, $r_{2}$ statically set to $0.1$.

<p align="center" width="100%">
    <a href="https://imgur.com/1Aas09P"><img src="https://i.imgur.com/1Aas09P.gif" title="source: imgur.com" width="49%" /></a>
    <a href="https://imgur.com/avzNVGQ"><img src="https://i.imgur.com/avzNVGQ.gif" title="source: imgur.com" width="49%" /></a>
</p>

Also, repoted below there are the gif of the optimization process on other fitness functions. 

<p align="center" width="100%">
    <a href="https://imgur.com/h6mm9Fl"><img src="https://i.imgur.com/h6mm9Fl.gif" title="source: imgur.com" width="49%" /></a>
    <a href="https://imgur.com/lhus5DC"><img src="https://i.imgur.com/lhus5DC.gif" title="source: imgur.com" width="49%" /></a>
</p>

<p align="center" width="100%">
    <a href="https://imgur.com/PegfxGG"><img src="https://i.imgur.com/PegfxGG.gif" title="source: imgur.com" width="49%" /></a>
    <a href="https://imgur.com/NOHEUHP"><img src="https://i.imgur.com/NOHEUHP.gif" title="source: imgur.com" width="49%" /></a>
</p>



*Note: The figures report the optimization with the PSO using $r_{1}$, $r_{2}$ uniformly sampled from a uniform distribution in the range $[0.1,0.4]$.*


Here the full code:

```python

import numpy as np
import random
from matplotlib import pyplot as plt
from matplotlib import animation
from numpy import exp
from numpy import sqrt
from numpy import cos
from numpy import e
from numpy import pi

# source: https://towardsdatascience.com/swarm-intelligence-coding-and-visualising-particle-swarm-optimisation-in-python-253e1bd00772

problem = 'Rastrigin'
# I use the rastrigin function as an example
def fitness_fn(x,y):
  """Fitness function"""
  # Ackley
  return -20.0 * exp(-0.2 * sqrt(0.5 * (x**2 + y**2))) - exp(0.5 * (cos(2 * pi * x) + cos(2 * pi * y))) + e + 20
  # Griewank
  # source: https://spotpy.readthedocs.io/en/latest/Griewank/
  # return 1 + (x**2 + y**2)/4000 - cos(x/sqrt(2))*cos(y/sqrt(3))+1
  # Schwefel
  # return 418.9829*2 - x * sin( sqrt( abs( x )))-y*sin(sqrt(abs(y)))
  # Rosenbrock
  # source: https://spotpy.readthedocs.io/en/latest/Rosenbrock/
  # return (1-x)**2 + 100*(y-x**2)**2
  # Rastrigin 
  # return 10*2 + x**2 + y**2 - 10*cos(2*pi*x) - 10*cos(2*pi*y)


def update_v(velocity, particles, pbest, gbest):
  """ Update the velocity of the particles
  Implementation slide 12 group of slide
  on particle swarm optimization

  Args:
    velocity: velocity of the particles
    particles: current position of the particles
    pbest: best position of the particles
    gbest: best position of the swarm

  Output:
    new_velocity: updated velocity of the particles

  """
  # number of particles
  n_particles = len(particles)

  # fi determine the particle trajectory
  fi = random.uniform(0.1, 0.4)

  # initialize the weight formula 
  # slide 14 (convergence condition)
  w = random.uniform((0.5*(fi+fi)), 1)

  # initialize the velocity to zero
  new_velocity = np.array([0.0 for _ in range(n_particles)])

  # random number piked from a uniform distribution
  u1 = random.uniform(0,1)
  u2 = random.uniform(0,1)

  # update the velocity
  for i in range(n_particles):
    # slide 12
    new_velocity[i] = w * velocity[i] + fi * u1 * (pbest[i] - particles[i]) + fi * u2 * (gbest[i] - particles[i])

  return new_velocity


def update_p(particle, velocity):
  """Update the position of the particles

  Args:
    particle: current position of the particles
    velocity: velocity of the particles

  Output:
    _ : updated position of the particles

  """
  return particle + velocity

def fit(population: int = 30, dimension: int = 2, generation: int = 100, pos_min: int = -200, pos_max: int = 200):

  # Plotting prepartion
  fig = plt.figure(figsize=(10, 10))
  ax = fig.add_subplot(111, projection='3d')
  ax.set_xlabel('x')
  ax.set_ylabel('y')
  ax.set_zlabel('z')
  x = np.linspace(pos_min, pos_max, 100)
  y = np.linspace(pos_min, pos_max, 100)
  X, Y = np.meshgrid(x, y)
  Z= fitness_fn(X,Y)
  ax.plot_wireframe(X, Y, Z, color='r', linewidth=0.2)

  # Animation image placeholder
  images = []

  # initialize the population
  particles = [[random.uniform(pos_min, pos_max) for j in range(dimension)] for i in range(population)]

  # compute the fitness of the particles
  pfitness = [fitness_fn(p[0],p[1]) for p in particles]

  # index particle with the best fitness
  index_gbest = np.argmin(pfitness)

  # position of the particle with the best fitness
  position_gbest = particles[index_gbest]

  # initialize the velocity equal to zero
  velocity = [[0.0 for j in range(dimension)] for i in range(population)]

  for _ in range(generation):

    for i in range(population):
      # update the velocity
      velocity[i] = update_v(velocity[i], particles[i], particles[i], position_gbest)

      # update the position
      particles[i] = update_p(particles[i], velocity[i])


    # Plotting
    image = ax.scatter3D([particles[n][0] for n in range(population)],
                        [particles[n][1] for n in range(population)],
                        [fitness_fn(particles[n][0],particles[n][1]) for n in range(population)], c='b')
    images.append([image])

    # compute the fitness of the particles
    pfitness = [fitness_fn(p[0],p[1]) for p in particles]

    # index particle with the best fitness
    index_gbest = np.argmin(pfitness)

    # position of the particle with the best fitness
    position_gbest = particles[index_gbest]

  # Generate the animation image and save
  animated_image = animation.ArtistAnimation(fig, images, interval=5, blit=True, repeat_delay=1000)
  animated_image.save(f'./gif_pso_swarm_simulation{problem}.mp4', fps=20) 

  return position_gbest, pfitness[index_gbest], np.average(pfitness), images

position_gbest, pfitness, average_fitness, images = fit()
```

---
References:

1. [Topology Optimization of Particle Swarm Optimization](https://link.springer.com/chapter/10.1007/978-3-319-11857-4_16)
2. [Particle swarm optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization)
3. [Analysis of the Publications on the Applications of Particle Swarm Optimisation](https://onlinelibrary.wiley.com/doi/10.1155/2008/685175)
4. [Particle swarm optimization](https://en.wikipedia.org/wiki/Particle_swarm_optimization)

---