---
layout: post
title: Matrix multiplication from C++ to CUDA
date: 2020-05-16 15:09:00
description: an example of matrix multiplication in C++ and CUDA
tags: C++ CUDA matrix-multiplication parallel-computing GPU
categories: programming
featured: true
---

The following code is a simple matrix multiplication tutorial proposing a comparison between the sequential and parallel implementation (C++ and CUDA). The CUDA documentation is available [here](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html). 

#### C++ implementation

First things first, we need to import for the C++ implementation the following libraries:
```c++
#include <iostream> 
#include <vector> // for vector
#include <thread>
#include <chrono> // for time

using namespace std;
```
We define the matrix class as follows, the matrix is a vector of vectors of integers. The constructor initialises the matrix with zeros and takes the number of rows and columns as input. The set and get methods are used to set and get the value of an element of the array. The print method is used to print the matrix.

```c++
// Matrix class
class Matrix {
    private:
        int rows;
        int cols;
        vector<vector<int>> matrix;
    public:
        Matrix(int rows, int cols) {
            this->rows = rows;
            this->cols = cols;
            this->matrix = vector<vector<int>>(rows, vector<int>(cols, 0));
        }
        void set(int row, int col, int value) {
            this->matrix[row][col] = value;
        }
        int get(int row, int col) {
            return this->matrix[row][col];
        }
        int getRows() {
            return this->rows;
        }
        int getCols() {
            return this->cols;
        }
        void print() {
            for (int i = 0; i < this->rows; i++) {
                for (int j = 0; j < this->cols; j++) {
                    std::cout << this->matrix[i][j] << " ";
                }
                std::cout << endl;
            }
        }
};
```
Then, we define the matrix multiplication function. The function takes as input three matrices, the first two are the matrices to multiply and the third is the matrix the resulting matrix after the multiplication. Start and end can be used to specify the range of rows to compute. Thus, the function can be used in parallel, and the results can be joined at the end.

The function iterates over the rows of the first matrix and the columns of the second matrix and computes the value of the element of the result matrix. To update the values in the third matrix, we use the set method defined in the matrix class.

```c++
// Matrix multiplication
void multiply(Matrix *A, Matrix *B, Matrix *C, int start, int end) {
    int rows = A->getRows();
    int cols = B->getCols();
    int k = A->getCols();
    for (int i = start; i < end; i++) {
        for (int j = 0; j < cols; j++) {
            int sum = 0;
            for (int l = 0; l < k; l++) {
                sum += A->get(i, l) * B->get(l, j);
            }
            C->set(i, j, sum);
        }
    }
}
```

In order to keep the code in the main clean, we define a function to initialise the matrices. The function takes as input the number of rows and columns and returns a matrix initialised with ones.

```c++
// Instantiate matrices
Matrix InitMatrix(int rows, int cols) {
    Matrix matrix(rows, cols);
    for (int i = 0; i < rows; i++) {
        for (int j = 0; j < cols; j++) {
            matrix.set(i, j, 1);
        }
        
    }
    return matrix;
}
```
In the main we define the dimensions of the matrices and instantiate them. Then, we start the timer, to measure the time of the computation. This is useful to check the speedup of the parallel implementation. After the computation, we stop the timer and print the result and the time.

```c++
// Main function
int main() {
    // Matrix dimensions
    int rowsA = 10;
    int colsA = 10;
    int rowsB = colsA;
    int colsB = 10;
    int rowsC = rowsA;
    int colsC = colsB;

    // Instantiate matrices
    Matrix A = InitMatrix(rowsA, colsA);
    Matrix B = InitMatrix(rowsB, colsB);
    Matrix C = Matrix(rowsC, colsC);
    
    // Start timer
    auto start = chrono::high_resolution_clock::now();

    // Multiply matrices
    multiply(&A, &B, &C, 0, rowsC);

    // Stop timer
    auto stop = chrono::high_resolution_clock::now();
    auto duration = chrono::duration_cast<chrono::microseconds>(stop - start);

    // Print result
    std::cout << "Result:" << std::endl;
    C.print();

    // Print time
    std::cout << "Time: " << duration.count() << " microseconds" << std::endl;

    return 0;

}
```
Here is the output of the program:

```bash
rick@book:~/Desktop/MatMul#~ g++ -std=c++11 -o main main.cpp && ./main
Result:
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
10 10 10 10 10 10 10 10 10 10 
Time: 12 microseconds
```

Brief recap of the code:
```c++
#include <iostream>
#include <vector>
#include <thread>
#include <chrono>

using namespace std;

// Matrix class
class Matrix {
    private:
        int rows;
        int cols;
        vector<vector<int>> matrix;
    public:
        Matrix(int rows, int cols) {
            this->rows = rows;
            this->cols = cols;
            this->matrix = vector<vector<int>>(rows, vector<int>(cols, 0));
        }
        void set(int row, int col, int value) {
            this->matrix[row][col] = value;
        }
        int get(int row, int col) {
            return this->matrix[row][col];
        }
        int getRows() {
            return this->rows;
        }
        int getCols() {
            return this->cols;
        }
        void print() {
            for (int i = 0; i < this->rows; i++) {
                for (int j = 0; j < this->cols; j++) {
                    std::cout << this->matrix[i][j] << " ";
                }
                std::cout << endl;
            }
        }
};


// Matrix multiplication
void multiply(Matrix *A, Matrix *B, Matrix *C, int start, int end) {
    int rows = A->getRows();
    int cols = B->getCols();
    int k = A->getCols();
    for (int i = start; i < end; i++) {
        for (int j = 0; j < cols; j++) {
            int sum = 0;
            for (int l = 0; l < k; l++) {
                sum += A->get(i, l) * B->get(l, j);
            }
            C->set(i, j, sum);
        }
    }
}

// Instantiate matrices
Matrix InitMatrix(int rows, int cols) {
    Matrix matrix(rows, cols);
    for (int i = 0; i < rows; i++) {
        for (int j = 0; j < cols; j++) {
            matrix.set(i, j, 1);
        }
        
    }
    return matrix;
}


// Main function
int main() {
    // Matrix dimensions
    int rowsA = 10;
    int colsA = 10;
    int rowsB = colsA;
    int colsB = 10;
    int rowsC = rowsA;
    int colsC = colsB;

    // Instantiate matrices
    Matrix A = InitMatrix(rowsA, colsA);
    Matrix B = InitMatrix(rowsB, colsB);
    Matrix C = Matrix(rowsC, colsC);
    
    // Start timer
    auto start = chrono::high_resolution_clock::now();

    // Multiply matrices
    multiply(&A, &B, &C, 0, rowsC);

    // Stop timer
    auto stop = chrono::high_resolution_clock::now();
    auto duration = chrono::duration_cast<chrono::microseconds>(stop - start);

    // Print result
    std::cout << "Result:" << std::endl;
    C.print();

    // Print time
    std::cout << "Time: " << duration.count() << " microseconds" << std::endl;

    return 0;

}
```

#### CUDA implementation

Now we take a look at the CUDA implementation. First, we need to import the CUDA libraries. The following code is the same as the C++ implementation, but we need to add the CUDA libraries.

```c++
// import cuda
#import<cuda.h>
#import<cuda_runtime.h>
#import<cuda_runtime_api.h>

// import stdio
#import<stdio.h>
```

Then, we define the matrix multiplication kernel. The kernel takes as input three matrices, the first two are the matrices to multiply and the third is the matrix the resulting matrix after the multiplication. The kernel iterates over the rows of the first matrix and the columns of the second matrix and computes the value of the element of the result matrix. 

```c++
// calculate row and column index of element
int row = blockIdx.y * blockDim.y + threadIdx.y;
int col = blockIdx.x * blockDim.x + threadIdx.x;
```

Specifically, at the real beginning of the kernel, we calculate the row and column index of the element. The row index is calculated by multiplying the block index in the y by the block dimension and adding the thread index in the y. Also, the column index is computed in the same way in the x dimension. This allows us to split the work and assign it to different threads, eventually, in different blocks. 

```c++
// matrix multiplication kernel called by MatMul()
__global__ void MatMulKernel(float* A, float* B, float* C, int N)
{
    // calculate row and column index of element
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    // calculate element value
    if (row < N && col < N)
    {
        float sum = 0;
        for (int i = 0; i < N; i++)
        {
            sum += A[row * N + i] * B[i * N + col];
        }
        C[row * N + col] = sum;
    }
}
```
The following function is used to call the kernel. The function allocates the memory on the device, copies the data from the host to the device, launches the kernel, copies the data from the device to the host and frees the memory on the device.

```c++
void MatMul(float* A, float* B, float* C, int N)
{
    // declare device memory pointers
    float* d_A;
    float* d_B;
    float* d_C;

    // allocate device memory
    cudaMalloc((void**)&d_A, N * N * sizeof(float));
    cudaMalloc((void**)&d_B, N * N * sizeof(float));
    cudaMalloc((void**)&d_C, N * N * sizeof(float));

    // copy data from host to device
    cudaMemcpy(d_A, A, N * N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, N * N * sizeof(float), cudaMemcpyHostToDevice);

    // define block and grid dimensions
    dim3 dimBlock(16, 16);
    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);

    // launch kernel
    MatMulKernel<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);

    // copy data from device to host
    cudaMemcpy(C, d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);

    // free device memory
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
}
```

Previously, we defined a function to initialise the matrices. Now, we need to define a function to print the matrix.

```c++
// print matrix function
void printMatrix(float* A, int N)
{
    for (int i = 0; i < N * N; i++)
    {
        printf("%f ", A[i]);
        if ((i + 1) % N == 0)
        {
            printf("\n");
        }
    }
}
```

The main function is the same as the C++ implementation, but we initialise the matrix as a single array of floats. This is because CUDA does not support vectors of vectors. 

```c++
// main function
int main(){
    // define matrix size
    int N = 10;

    // declare and allocate host memory
    float* A = (float*)malloc(N * N * sizeof(float));
    float* B = (float*)malloc(N * N * sizeof(float));
    float* C = (float*)malloc(N * N * sizeof(float));

    // initialize host memory
    for (int i = 0; i < N * N; i++)
    {
        A[i] = 1.0;
        B[i] = 1.0;
        C[i] = 0.0;
    }

    // call matrix multiplication function
    MatMul(A, B, C, N);

    // print matrix
    printMatrix(C, N);

    // free host memory
    free(A);
    free(B);
    free(C);

    return 0;
}
```

Here is the output:
```bash
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
10 10 10 10 10 10 10 10 10 10
CPU times: user 24.9 ms, sys: 5.85 ms, total: 30.7 ms
Wall time: 31.1 ms
```

To recap:
```c++
// how to run the code 
// load the file.cu on colab 
// then, to run the code, type and run in a jupyter cell 
// the following command:
// !nvcc file.cu -o file && ./file

// import cuda
#import<cuda.h>
#import<cuda_runtime.h>
#import<cuda_runtime_api.h>

// import stdio
#import<stdio.h>


// matrix multiplication kernel called by MatMul()
__global__ void MatMulKernel(float* A, float* B, float* C, int N)
{
    // calculate row and column index of element
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    // calculate element value
    if (row < N && col < N)
    {
        float sum = 0;
        for (int i = 0; i < N; i++)
        {
            sum += A[row * N + i] * B[i * N + col];
        }
        C[row * N + col] = sum;
    }
}

// matrix multiplication function called by main()
void MatMul(float* A, float* B, float* C, int N)
{
    // declare device memory pointers
    float* d_A;
    float* d_B;
    float* d_C;

    // allocate device memory
    cudaMalloc((void**)&d_A, N * N * sizeof(float));
    cudaMalloc((void**)&d_B, N * N * sizeof(float));
    cudaMalloc((void**)&d_C, N * N * sizeof(float));

    // copy data from host to device
    cudaMemcpy(d_A, A, N * N * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, B, N * N * sizeof(float), cudaMemcpyHostToDevice);

    // define block and grid dimensions
    dim3 dimBlock(16, 16);
    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);

    // launch kernel
    MatMulKernel<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);

    // copy data from device to host
    cudaMemcpy(C, d_C, N * N * sizeof(float), cudaMemcpyDeviceToHost);

    // free device memory
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
}

// print matrix function
void printMatrix(float* A, int N)
{
    for (int i = 0; i < N * N; i++)
    {
        printf("%f ", A[i]);
        if ((i + 1) % N == 0)
        {
            printf("\n");
        }
    }
}

// main function
int main(){
    // define matrix size
    int N = 10;

    // declare and allocate host memory
    float* A = (float*)malloc(N * N * sizeof(float));
    float* B = (float*)malloc(N * N * sizeof(float));
    float* C = (float*)malloc(N * N * sizeof(float));

    // initialize host memory
    for (int i = 0; i < N * N; i++)
    {
        A[i] = 1.0;
        B[i] = 1.0;
        C[i] = 0.0;
    }

    // call matrix multiplication function
    MatMul(A, B, C, N);

    // print matrix
    printMatrix(C, N);

    // free host memory
    free(A);
    free(B);
    free(C);

    return 0;
}
```

#### Speedup

The speedup is the ratio between the time of the sequential implementation and the time of the parallel implementation is not significant on small matrices. However, on large matrices, the speedup is significant. Here is the output of the program on a 1000x1000 matrix and a 10000x10000 matrix.


```bash
//// MATRIX 1000x1000 

// Sequential implementation
Result:
Time: 9,57 s

// CUDA implementation on T4 GPU
CPU times: user 18.6 ms, sys: 5.12 ms, total: 23.7 ms
Wall time: 2.11 s
```

```bash
//// MATRIX 10000x10000 

// Sequential implementation
Result:
Time: 16 min

// CUDA implementation on T4 GPU
CPU times: user 55.9 ms, sys: 7.25 ms, total: 63.2 ms
Wall time: 8.94 s
```